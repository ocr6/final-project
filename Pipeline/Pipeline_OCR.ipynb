{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pipeline OCR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library"
      ],
      "metadata": {
        "id": "um523rnB6fOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "from skimage import io\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import string"
      ],
      "metadata": {
        "id": "VvoLgLpz6lZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Sample Image"
      ],
      "metadata": {
        "id": "FGT7t3wY5ZSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsUTkSgxFyi4",
        "outputId": "58509712-d61f-4925-8bae-f4f353bc848b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2ZaXqgm487-"
      },
      "outputs": [],
      "source": [
        "test_image_path = '/content/drive/MyDrive/OCR/ImageAndXML_Data/0000223278.tif'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Detection"
      ],
      "metadata": {
        "id": "cELPuIQB51AI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O craft.tflite 'https://tfhub.dev/tulasiram58827/lite-model/craft-text-detector/float16/1?lite-format=tflite'\n",
        "craft_tflite = '/content/craft.tflite'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETb4Jbgm56Av",
        "outputId": "26cee033-6f33-419c-fecf-518208ed7fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-27 14:38:11--  https://tfhub.dev/tulasiram58827/lite-model/craft-text-detector/float16/1?lite-format=tflite\n",
            "Resolving tfhub.dev (tfhub.dev)... 142.251.16.139, 142.251.16.138, 142.251.16.102, ...\n",
            "Connecting to tfhub.dev (tfhub.dev)|142.251.16.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com/tfhub-lite-models/tulasiram58827/lite-model/craft-text-detector/float16/1.tflite [following]\n",
            "--2022-07-27 14:38:11--  https://storage.googleapis.com/tfhub-lite-models/tulasiram58827/lite-model/craft-text-detector/float16/1.tflite\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.62.128, 172.253.115.128, 172.253.122.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.62.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41627008 (40M) [application/octet-stream]\n",
            "Saving to: ‘craft.tflite’\n",
            "\n",
            "craft.tflite        100%[===================>]  39.70M   122MB/s    in 0.3s    \n",
            "\n",
            "2022-07-27 14:38:11 (122 MB/s) - ‘craft.tflite’ saved [41627008/41627008]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Important Functions\n",
        "def loadImage(img_file):\n",
        "    img = io.imread(img_file)           # RGB order\n",
        "    if img.shape[0] == 2: img = img[0]\n",
        "    if len(img.shape) == 2 : img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    if img.shape[2] == 4:   img = img[:,:,:3]\n",
        "    img = np.array(img)\n",
        "\n",
        "    return img\n",
        "\n",
        "def normalizeMeanVariance(in_img, mean=(0.485, 0.456, 0.406), variance=(0.229, 0.224, 0.225)):\n",
        "    # should be RGB order\n",
        "    img = in_img.copy().astype(np.float32)\n",
        "\n",
        "    img -= np.array([mean[0] * 255.0, mean[1] * 255.0, mean[2] * 255.0], dtype=np.float32)\n",
        "    img /= np.array([variance[0] * 255.0, variance[1] * 255.0, variance[2] * 255.0], dtype=np.float32)\n",
        "    return img\n",
        "\n",
        "def denormalizeMeanVariance(in_img, mean=(0.485, 0.456, 0.406), variance=(0.229, 0.224, 0.225)):\n",
        "    # should be RGB order\n",
        "    img = in_img.copy()\n",
        "    img *= variance\n",
        "    img += mean\n",
        "    img *= 255.0\n",
        "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
        "    return img\n",
        "\n",
        "def resize_aspect_ratio(img, square_size, interpolation, mag_ratio=1):\n",
        "    height, width, channel = img.shape\n",
        "\n",
        "    # magnify image size\n",
        "    target_size = mag_ratio * max(height, width)\n",
        "\n",
        "    # set original image size\n",
        "    if target_size > square_size:\n",
        "        target_size = square_size\n",
        "    \n",
        "    ratio = target_size / max(height, width)    \n",
        "\n",
        "    target_h, target_w = int(height * ratio), int(width * ratio)\n",
        "    proc = cv2.resize(img, (target_w, target_h), interpolation = interpolation)\n",
        "\n",
        "\n",
        "    # make canvas and paste image\n",
        "    target_h32, target_w32 = target_h, target_w\n",
        "    if target_h % 32 != 0:\n",
        "        target_h32 = target_h + (32 - target_h % 32)\n",
        "    if target_w % 32 != 0:\n",
        "        target_w32 = target_w + (32 - target_w % 32)\n",
        "    resized = np.zeros((target_h32, target_w32, channel), dtype=np.float32)\n",
        "    resized[0:target_h, 0:target_w, :] = proc\n",
        "    target_h, target_w = target_h32, target_w32\n",
        "\n",
        "    size_heatmap = (int(target_w/2), int(target_h/2))\n",
        "\n",
        "    return resized, ratio, size_heatmap\n",
        "\n",
        "def saveResult(img_file, img, boxes, dirname='./result/', verticals=None, texts=None):\n",
        "        \"\"\" save text detection result one by one\n",
        "        Args:\n",
        "            img_file (str): image file name\n",
        "            img (array): raw image context\n",
        "            boxes (array): array of result file\n",
        "                Shape: [num_detections, 4] for BB output / [num_detections, 4] for QUAD output\n",
        "        Return:\n",
        "            None\n",
        "        \"\"\"\n",
        "        img = np.array(img)\n",
        "\n",
        "        # make result file list\n",
        "        filename, file_ext = os.path.splitext(os.path.basename(img_file))\n",
        "\n",
        "        # result directory\n",
        "        res_file = dirname + \"res_\" + filename + '.txt'\n",
        "        res_img_file = dirname + \"res_\" + filename + '.jpg'\n",
        "\n",
        "        if not os.path.isdir(dirname):\n",
        "            os.mkdir(dirname)\n",
        "        #data = open('task3.txt', 'w')\n",
        "        count = 0\n",
        "        with open(res_file, 'w') as f:\n",
        "            for i, box in enumerate(boxes):\n",
        "                #text = save_polygon(img, box, count)\n",
        "                #box_data = \"\"\n",
        "                #for co_ord in box:\n",
        "                #    box_data+=f\"{co_ord[0]}, {co_ord[1]}\"\n",
        "                #print(box_data, text)\n",
        "                #data.write(box_data+\",\"+text+\"\\n\")\n",
        "                #count+=1\n",
        "                poly = np.array(box).astype(np.int32).reshape((-1))\n",
        "                #strResult = ','.join([str(p) for p in poly]) + '\\r\\n'\n",
        "                #f.write(strResult)\n",
        "                poly = poly.reshape(-1, 2)\n",
        "                min_co = tuple(np.min(poly, axis=0))\n",
        "                max_co = tuple(np.max(poly, axis=0))\n",
        "                #x_1, x_2, y_1, y_2 = poly[0][0], poly[1][0], poly[1][1], poly[2][1]\n",
        "                cv2.rectangle(img, min_co, max_co, (0, 0, 255), 2)\n",
        "                #cv2.polylines(img, [poly.reshape((-1, 1, 2))], True, color=(0, 0, 255), thickness=2)\n",
        "                ptColor = (0, 255, 255)\n",
        "                if verticals is not None:\n",
        "                    if verticals[i]:\n",
        "                        ptColor = (255, 0, 0)\n",
        "\n",
        "                if texts is not None:\n",
        "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "                    font_scale = 0.5\n",
        "                    cv2.putText(img, \"{}\".format(texts[i]), (poly[0][0]+1, poly[0][1]+1), font, font_scale, (0, 0, 0), thickness=1)\n",
        "                    cv2.putText(img, \"{}\".format(texts[i]), tuple(poly[0]), font, font_scale, (0, 255, 255), thickness=1)\n",
        "\n",
        "        # Save result image\n",
        "        cv2.imwrite(res_img_file, img)\n",
        "\n",
        "\"\"\" auxilary functions \"\"\"\n",
        "# unwarp corodinates\n",
        "def warpCoord(Minv, pt):\n",
        "    out = np.matmul(Minv, (pt[0], pt[1], 1))\n",
        "    return np.array([out[0]/out[2], out[1]/out[2]])\n",
        "\"\"\" end of auxilary functions \"\"\"\n",
        "\n",
        "\n",
        "def getDetBoxes_core(textmap, linkmap, text_threshold, link_threshold, low_text):\n",
        "    # prepare data\n",
        "    linkmap = linkmap.copy()\n",
        "    textmap = textmap.copy()\n",
        "    img_h, img_w = textmap.shape\n",
        "\n",
        "    \"\"\" labeling method \"\"\"\n",
        "    ret, text_score = cv2.threshold(textmap, low_text, 1, 0)\n",
        "    ret, link_score = cv2.threshold(linkmap, link_threshold, 1, 0)\n",
        "\n",
        "    text_score_comb = np.clip(text_score + link_score, 0, 1)\n",
        "    nLabels, labels, stats, centroids = cv2.connectedComponentsWithStats(text_score_comb.astype(np.uint8), connectivity=4)\n",
        "\n",
        "    det = []\n",
        "    mapper = []\n",
        "    for k in range(1,nLabels):\n",
        "        # size filtering\n",
        "        size = stats[k, cv2.CC_STAT_AREA]\n",
        "        if size < 10: continue\n",
        "\n",
        "        # thresholding\n",
        "        if np.max(textmap[labels==k]) < text_threshold: continue\n",
        "\n",
        "        # make segmentation map\n",
        "        segmap = np.zeros(textmap.shape, dtype=np.uint8)\n",
        "        segmap[labels==k] = 255\n",
        "        segmap[np.logical_and(link_score==1, text_score==0)] = 0   # remove link area\n",
        "        x, y = stats[k, cv2.CC_STAT_LEFT], stats[k, cv2.CC_STAT_TOP]\n",
        "        w, h = stats[k, cv2.CC_STAT_WIDTH], stats[k, cv2.CC_STAT_HEIGHT]\n",
        "        niter = int(math.sqrt(size * min(w, h) / (w * h)) * 2)\n",
        "        sx, ex, sy, ey = x - niter, x + w + niter + 1, y - niter, y + h + niter + 1\n",
        "        # boundary check\n",
        "        if sx < 0 : sx = 0\n",
        "        if sy < 0 : sy = 0\n",
        "        if ex >= img_w: ex = img_w\n",
        "        if ey >= img_h: ey = img_h\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(1 + niter, 1 + niter))\n",
        "        segmap[sy:ey, sx:ex] = cv2.dilate(segmap[sy:ey, sx:ex], kernel)\n",
        "\n",
        "        # make box\n",
        "        np_contours = np.roll(np.array(np.where(segmap!=0)),1,axis=0).transpose().reshape(-1,2)\n",
        "        rectangle = cv2.minAreaRect(np_contours)\n",
        "        box = cv2.boxPoints(rectangle)\n",
        "\n",
        "        # align diamond-shape\n",
        "        w, h = np.linalg.norm(box[0] - box[1]), np.linalg.norm(box[1] - box[2])\n",
        "        box_ratio = max(w, h) / (min(w, h) + 1e-5)\n",
        "        if abs(1 - box_ratio) <= 0.1:\n",
        "            l, r = min(np_contours[:,0]), max(np_contours[:,0])\n",
        "            t, b = min(np_contours[:,1]), max(np_contours[:,1])\n",
        "            box = np.array([[l, t], [r, t], [r, b], [l, b]], dtype=np.float32)\n",
        "\n",
        "        # make clock-wise order\n",
        "        startidx = box.sum(axis=1).argmin()\n",
        "        box = np.roll(box, 4-startidx, 0)\n",
        "        box = np.array(box)\n",
        "\n",
        "        det.append(box)\n",
        "        mapper.append(k)\n",
        "\n",
        "    return det, labels, mapper\n",
        "\n",
        "def getPoly_core(boxes, labels, mapper, linkmap):\n",
        "    # configs\n",
        "    num_cp = 5\n",
        "    max_len_ratio = 0.7\n",
        "    expand_ratio = 1.45\n",
        "    max_r = 2.0\n",
        "    step_r = 0.2\n",
        "\n",
        "    polys = []  \n",
        "    for k, box in enumerate(boxes):\n",
        "        # size filter for small instance\n",
        "        w, h = int(np.linalg.norm(box[0] - box[1]) + 1), int(np.linalg.norm(box[1] - box[2]) + 1)\n",
        "        if w < 10 or h < 10:\n",
        "            polys.append(None); continue\n",
        "\n",
        "        # warp image\n",
        "        tar = np.float32([[0,0],[w,0],[w,h],[0,h]])\n",
        "        M = cv2.getPerspectiveTransform(box, tar)\n",
        "        word_label = cv2.warpPerspective(labels, M, (w, h), flags=cv2.INTER_NEAREST)\n",
        "        try:\n",
        "            Minv = np.linalg.inv(M)\n",
        "        except:\n",
        "            polys.append(None); continue\n",
        "\n",
        "        # binarization for selected label\n",
        "        cur_label = mapper[k]\n",
        "        word_label[word_label != cur_label] = 0\n",
        "        word_label[word_label > 0] = 1\n",
        "\n",
        "        \"\"\" Polygon generation \"\"\"\n",
        "        # find top/bottom contours\n",
        "        cp = []\n",
        "        max_len = -1\n",
        "        for i in range(w):\n",
        "            region = np.where(word_label[:,i] != 0)[0]\n",
        "            if len(region) < 2 : continue\n",
        "            cp.append((i, region[0], region[-1]))\n",
        "            length = region[-1] - region[0] + 1\n",
        "            if length > max_len: max_len = length\n",
        "\n",
        "        # pass if max_len is similar to h\n",
        "        if h * max_len_ratio < max_len:\n",
        "            polys.append(None); continue\n",
        "\n",
        "        # get pivot points with fixed length\n",
        "        tot_seg = num_cp * 2 + 1\n",
        "        seg_w = w / tot_seg     # segment width\n",
        "        pp = [None] * num_cp    # init pivot points\n",
        "        cp_section = [[0, 0]] * tot_seg\n",
        "        seg_height = [0] * num_cp\n",
        "        seg_num = 0\n",
        "        num_sec = 0\n",
        "        prev_h = -1\n",
        "        for i in range(0,len(cp)):\n",
        "            (x, sy, ey) = cp[i]\n",
        "            if (seg_num + 1) * seg_w <= x and seg_num <= tot_seg:\n",
        "                # average previous segment\n",
        "                if num_sec == 0: break\n",
        "                cp_section[seg_num] = [cp_section[seg_num][0] / num_sec, cp_section[seg_num][1] / num_sec]\n",
        "                num_sec = 0\n",
        "\n",
        "                # reset variables\n",
        "                seg_num += 1\n",
        "                prev_h = -1\n",
        "\n",
        "            # accumulate center points\n",
        "            cy = (sy + ey) * 0.5\n",
        "            cur_h = ey - sy + 1\n",
        "            cp_section[seg_num] = [cp_section[seg_num][0] + x, cp_section[seg_num][1] + cy]\n",
        "            num_sec += 1\n",
        "\n",
        "            if seg_num % 2 == 0: continue # No polygon area\n",
        "\n",
        "            if prev_h < cur_h:\n",
        "                pp[int((seg_num - 1)/2)] = (x, cy)\n",
        "                seg_height[int((seg_num - 1)/2)] = cur_h\n",
        "                prev_h = cur_h\n",
        "\n",
        "        # processing last segment\n",
        "        if num_sec != 0:\n",
        "            cp_section[-1] = [cp_section[-1][0] / num_sec, cp_section[-1][1] / num_sec]\n",
        "\n",
        "        # pass if num of pivots is not sufficient or segment widh is smaller than character height \n",
        "        if None in pp or seg_w < np.max(seg_height) * 0.25:\n",
        "            polys.append(None); continue\n",
        "\n",
        "        # calc median maximum of pivot points\n",
        "        half_char_h = np.median(seg_height) * expand_ratio / 2\n",
        "\n",
        "        # calc gradiant and apply to make horizontal pivots\n",
        "        new_pp = []\n",
        "        for i, (x, cy) in enumerate(pp):\n",
        "            dx = cp_section[i * 2 + 2][0] - cp_section[i * 2][0]\n",
        "            dy = cp_section[i * 2 + 2][1] - cp_section[i * 2][1]\n",
        "            if dx == 0:     # gradient if zero\n",
        "                new_pp.append([x, cy - half_char_h, x, cy + half_char_h])\n",
        "                continue\n",
        "            rad = - math.atan2(dy, dx)\n",
        "            c, s = half_char_h * math.cos(rad), half_char_h * math.sin(rad)\n",
        "            new_pp.append([x - s, cy - c, x + s, cy + c])\n",
        "\n",
        "        # get edge points to cover character heatmaps\n",
        "        isSppFound, isEppFound = False, False\n",
        "        grad_s = (pp[1][1] - pp[0][1]) / (pp[1][0] - pp[0][0]) + (pp[2][1] - pp[1][1]) / (pp[2][0] - pp[1][0])\n",
        "        grad_e = (pp[-2][1] - pp[-1][1]) / (pp[-2][0] - pp[-1][0]) + (pp[-3][1] - pp[-2][1]) / (pp[-3][0] - pp[-2][0])\n",
        "        for r in np.arange(0.5, max_r, step_r):\n",
        "            dx = 2 * half_char_h * r\n",
        "            if not isSppFound:\n",
        "                line_img = np.zeros(word_label.shape, dtype=np.uint8)\n",
        "                dy = grad_s * dx\n",
        "                p = np.array(new_pp[0]) - np.array([dx, dy, dx, dy])\n",
        "                cv2.line(line_img, (int(p[0]), int(p[1])), (int(p[2]), int(p[3])), 1, thickness=1)\n",
        "                if np.sum(np.logical_and(word_label, line_img)) == 0 or r + 2 * step_r >= max_r:\n",
        "                    spp = p\n",
        "                    isSppFound = True\n",
        "            if not isEppFound:\n",
        "                line_img = np.zeros(word_label.shape, dtype=np.uint8)\n",
        "                dy = grad_e * dx\n",
        "                p = np.array(new_pp[-1]) + np.array([dx, dy, dx, dy])\n",
        "                cv2.line(line_img, (int(p[0]), int(p[1])), (int(p[2]), int(p[3])), 1, thickness=1)\n",
        "                if np.sum(np.logical_and(word_label, line_img)) == 0 or r + 2 * step_r >= max_r:\n",
        "                    epp = p\n",
        "                    isEppFound = True\n",
        "            if isSppFound and isEppFound:\n",
        "                break\n",
        "\n",
        "        # pass if boundary of polygon is not found\n",
        "        if not (isSppFound and isEppFound):\n",
        "            polys.append(None); continue\n",
        "\n",
        "        # make final polygon\n",
        "        poly = []\n",
        "        poly.append(warpCoord(Minv, (spp[0], spp[1])))\n",
        "        for p in new_pp:\n",
        "            poly.append(warpCoord(Minv, (p[0], p[1])))\n",
        "        poly.append(warpCoord(Minv, (epp[0], epp[1])))\n",
        "        poly.append(warpCoord(Minv, (epp[2], epp[3])))\n",
        "        for p in reversed(new_pp):\n",
        "            poly.append(warpCoord(Minv, (p[2], p[3])))\n",
        "        poly.append(warpCoord(Minv, (spp[2], spp[3])))\n",
        "\n",
        "        # add to final result\n",
        "        polys.append(np.array(poly))\n",
        "\n",
        "    return polys\n",
        "\n",
        "def getDetBoxes(textmap, linkmap, text_threshold, link_threshold, low_text, poly=False):\n",
        "    boxes, labels, mapper = getDetBoxes_core(textmap, linkmap, text_threshold, link_threshold, low_text)\n",
        "\n",
        "    if poly:\n",
        "        polys = getPoly_core(boxes, labels, mapper, linkmap)\n",
        "    else:\n",
        "        polys = [None] * len(boxes)\n",
        "\n",
        "    return boxes, polys\n",
        "\n",
        "def adjustResultCoordinates(polys, ratio_w, ratio_h, ratio_net = 2):\n",
        "    if len(polys) > 0:\n",
        "        polys = np.array(polys)\n",
        "        for k in range(len(polys)):\n",
        "            if polys[k] is not None:\n",
        "                polys[k] *= (ratio_w * ratio_net, ratio_h * ratio_net)\n",
        "    return polys\n",
        "\n",
        "def cvt2HeatmapImg(img):\n",
        "    img = (np.clip(img, 0, 1) * 255).astype(np.uint8)\n",
        "    img = cv2.applyColorMap(img, cv2.COLORMAP_JET)\n",
        "    return img\n",
        "    \n",
        "def run_tflite_model(input_data):\n",
        "    # Load the TFLite model and allocate tensors.\n",
        "    interpreter = tf.lite.Interpreter(model_path=craft_tflite)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Get input and output tensors.\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        " \n",
        "    # Test the model on random input data.\n",
        "    input_shape = input_details[0]['shape']\n",
        "    # input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # The function `get_tensor()` returns a copy of the tensor data.\n",
        "    # Use `tensor()` in order to get a pointer to the tensor.\n",
        "    y = interpreter.get_tensor(output_details[0]['index'])\n",
        "    feature = interpreter.get_tensor(output_details[1]['index'])\n",
        "\n",
        "    return y, feature\n"
      ],
      "metadata": {
        "id": "10rwyFZn5_kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "#Use any sample image.\n",
        "image_path = test_image_path\n",
        "start_time = time.time()\n",
        "image = loadImage(image_path)\n",
        "image = cv2.resize(image, dsize=(600, 800), interpolation=cv2.INTER_LINEAR)\n",
        "img_resized, target_ratio, size_heatmap = resize_aspect_ratio(image, 800, interpolation=cv2.INTER_LINEAR, mag_ratio=1)\n",
        "ratio_h = ratio_w = 1 / target_ratio\n",
        "\n",
        "# preprocessing\n",
        "x = normalizeMeanVariance(image)\n",
        "x = torch.from_numpy(x).permute(2, 0, 1)    # [h, w, c] to [c, h, w]\n",
        "x = Variable(x.unsqueeze(0))                # [c, h, w] to [b, c, h, w]\n",
        "# forward pass\n",
        "\n",
        "x = x.cpu().detach().numpy()\n",
        "y, feature = run_tflite_model(x)\n",
        "\n",
        "y = torch.from_numpy(y)\n",
        "feature = torch.from_numpy(feature)\n",
        "# make score and link map\n",
        "score_text = y[0,:,:,0].cpu().data.numpy()\n",
        "score_link = y[0,:,:,1].cpu().data.numpy()\n",
        "\n",
        "text_threshold = 0.7\n",
        "link_threshold = 0.4\n",
        "low_text = 0.4\n",
        "poly = False\n",
        "\n",
        "# Post-processing\n",
        "boxes, polys = getDetBoxes(score_text, score_link, text_threshold, link_threshold, low_text, poly)\n",
        "\n",
        "# coordinate adjustment\n",
        "boxes = adjustResultCoordinates(boxes, ratio_w, ratio_h)\n",
        "polys = adjustResultCoordinates(polys, ratio_w, ratio_h)\n",
        "for k in range(len(polys)):\n",
        "    if polys[k] is None: polys[k] = boxes[k]\n",
        "\n",
        "# render results (optional)\n",
        "render_img = score_text.copy()\n",
        "render_img = np.hstack((render_img, score_link))\n",
        "ret_score_text = cvt2HeatmapImg(render_img)\n",
        "\n",
        "\n",
        "saveResult(image_path, image[:,:,::-1], polys, dirname='output')\n",
        "filename, file_ext = os.path.splitext(os.path.basename(image_path))\n",
        "print(\"Total time taken to run CRAFT tflite model......\", time.time()-start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHE4TuOr6Rgj",
        "outputId": "559445e6-64fa-4362-b30b-3a00cd5c5cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time taken to run CRAFT tflite model...... 19.409886360168457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_images = []\n",
        "for box in boxes:\n",
        "    x1 = int(box[0][0]) \n",
        "    y1 = int(box[0][1])\n",
        "    x2 = int(box[2][0])\n",
        "    y2 = int(box[2][1])\n",
        "    ROI = image[y1:y2, x1:x2]\n",
        "    text_images.append(ROI)\n",
        "    "
      ],
      "metadata": {
        "id": "08D29a4s-_en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(text_images[3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "EdgnpNj5_bEB",
        "outputId": "88e01d9e-5946-4790-8ff0-48b8f21309a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=54x10 at 0x7F17B19A2D50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADYAAAAKCAIAAABwnzpcAAAEhElEQVR4nM1Ty0sbXxS+j5lMojPjo0ZaDaEmK0FFTCoaF22hKq5cCXYRGl1VUnHTBhQVEYVIyUZ00yroQgndtggFxReCUdOisdHWUMVJaB4SMcak00nmdjHiT+w/8Durex4f57vfOQcSQiRJOj09pSiKEIIx1ul0EEIAQDweTyQSylsxQsi9e/c4jrtxBUGQZRkhxHHcxcXF7WIAAEVR+/v7Dx48yM/PJ4SAf4wQwvN8Op2WJEnBEkIoitLpdDc1kBAiiuLz5889Hg8AgOf53d1dlUoFABgYGJienr5DcWxszGq1Ku7Hjx9fvnwJALBarfn5+ePj43coAgB+//5N0zTG+E5cqZRl2WazbWxsBAKBmxTHcTab7dWrVyzLXnclhCSTSYfDMTQ0FIlEZFlWgqIo9vb21tbW+ny+aDQ6MTHBcdzDhw8lSSKEZDKZzs5OmqZ7e3tTqdTl5eXKykpLS8vR0VFfX19TU1MgEOjo6NDr9V6vd2dnh+M4v98/NjZmMBhisdji4qLb7a6srHS73X6//9GjRyMjI/F4PBqNulyu3NzckZERhQZSiDMMw/N8Mpnkef5GCZVKxbKsxWIxGo1ardZisZSVlaVSqeXl5Ww26/P5tra2lBGr1WqWZTmOYxiGpunOzs7Xr18bjcaKigqMMc/zVVVVo6OjpaWlT548UavVX758ef/+fSQSGR4ebm1tLS8vr6ioYFm2oKBAq9X29PS0tLScn59fb8tt8QVBkCRJrVYrOqlUKghhLBZLp9MajQYA0NzcnJeX53A4pqamJicnm5qaQqHQv0tmNBrLysqUESkRmqbtdjuEEEKYSqXm5uY2Nzfr6uoaGxsZhrkDxxiXlJTcYNHtXHV1tUJlf39/bW1NmbgoirIsAwAQQg0NDR0dHQcHB93d3d+/f3/z5k1NTY2SvWMIIQBAW1sbhFBphhCCEMqynJeX9/bt2/b2doqinE7n6urqHWwqlfJ6vTfri5S/fvv2ze/3z8/P7+3tCYLw7t07n88Xj8ePjo6i0Wg4HI7FYgsLC58+fUokEk6n88ePH1arFUJ4fHwsCEI4HL66utre3v7169fm5mY6nQYAnJ+fDw4OXl1d7ezsJBIJAEAsFpuamgqFQpFIxGazAQAmJiaWlpY+f/68srJyeHh4dnYmCEJXV9fe3l55efn1YSk6vXjxYn19HSFkMBiKiop2d3efPXvGsuyHDx9ycnJMJpNOp1tbWwsGg9XV1bOzszMzM0+fPnU6nR6Ph2GYxsZGi8XicDgAABqNxu12m0ymyclJl8slSdL9+/fHx8fr6+vn5uYGBgYkSdLr9Vqt9uDg4M+fP/39/QsLCx6PB2NsNpspikII1dfX2+12RcjrKfj9/lAohBDKZrOyLGOMjUZjMpkMh8MQQoZhCgsLg8EgRVEY48ePH2ezWVEUNzY2MMaEEI1GU1xcfHJyghCiabquro5hmMPDw2AwCADIycmpqqpiWfbnz5+BQABjnM1mCSFKsdls/vr1qyiKAIBMJsOyrHI6FEX9p+K/m/S/sr/S0UTwVZhrlgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Recognition"
      ],
      "metadata": {
        "id": "USR6W1uVEvwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
        "from keras.models import Model\n",
        "from keras.activations import relu, sigmoid, softmax\n",
        "import keras.backend as K"
      ],
      "metadata": {
        "id": "AizMtMUYHUo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_recog_path = '/content/drive/MyDrive/OCR/text-recog-weight.hdf5'"
      ],
      "metadata": {
        "id": "wpx-I1kh_vWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_list = string.ascii_letters+string.digits"
      ],
      "metadata": {
        "id": "uYb-gSh_GtdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepocessing_image(img_file):\n",
        "    # read input image and convert into gray scale image\n",
        "    img = cv2.cvtColor(img_file, cv2.COLOR_BGR2GRAY)   \n",
        "    # convert each image of shape (32, 128, 1)\n",
        "    w, h = img.shape\n",
        "    if h > 128 or w > 32:\n",
        "#         continue\n",
        "        return img,True\n",
        "    if w < 32:\n",
        "        add_zeros = np.ones((32-w, h))*255\n",
        "        img = np.concatenate((img, add_zeros))\n",
        "\n",
        "    if h < 128:\n",
        "        add_zeros = np.ones((32, 128-h))*255\n",
        "        img = np.concatenate((img, add_zeros), axis=1)\n",
        "    \n",
        "    img = np.expand_dims(img , axis = 2)\n",
        "    \n",
        "\n",
        "    # Normalize each image\n",
        "    img = img/255.\n",
        "    return img,False"
      ],
      "metadata": {
        "id": "58K0DYTYG0hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_model(img_shape,char_length):\n",
        "  # input with shape of height=32 and width=128 \n",
        "  inputs = Input(shape=(32,128,1))\n",
        "  \n",
        "  # convolution layer with kernel size (3,3)\n",
        "  conv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)\n",
        "  # poolig layer with kernel size (2,2)\n",
        "  pool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n",
        "  \n",
        "  conv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)\n",
        "  pool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n",
        "  \n",
        "  conv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)\n",
        "  \n",
        "  conv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)\n",
        "  # poolig layer with kernel size (2,1)\n",
        "  pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
        "  \n",
        "  conv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)\n",
        "  # Batch normalization layer\n",
        "  batch_norm_5 = BatchNormalization()(conv_5)\n",
        "  \n",
        "  conv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)\n",
        "  batch_norm_6 = BatchNormalization()(conv_6)\n",
        "  pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
        "  \n",
        "  conv_7 = Conv2D(512, (2,2), activation = 'relu')(pool_6)\n",
        "  \n",
        "  squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
        "  \n",
        "  # bidirectional LSTM layers with units=128\n",
        "  blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(squeezed)\n",
        "  blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(blstm_1)\n",
        "  \n",
        "  outputs = Dense(char_length+1, activation = 'softmax')(blstm_2)\n",
        "\n",
        "  return inputs,outputs\n"
      ],
      "metadata": {
        "id": "gFc0lkVjG4vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_shape = (32,128,1)\n",
        "inputs,outputs = generate_model(img_shape,len(char_list))\n",
        "model_recog = Model(inputs,outputs)\n",
        "# load the saved best model weights\n",
        "model_recog.load_weights(model_recog_path)\n",
        "\n",
        "# model_recog.summary()\n",
        "def predict(image_file):\n",
        "  test_img,isSkip = prepocessing_image(image_file)\n",
        "  test_img = np.expand_dims(test_img, axis=0)\n",
        "  if isSkip:\n",
        "    # print('Picture size cannot more than 128,32')\n",
        "    return ''\n",
        "  else:\n",
        "    # predict outputs on validation images\n",
        "    prediction = model_recog.predict(test_img)\n",
        "\n",
        "    # use CTC decoder\n",
        "    out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],\n",
        "                            greedy=True)[0][0])\n",
        "\n",
        "    # see the results\n",
        "    i = 0\n",
        "    words = ''\n",
        "    for x in out:\n",
        "        for p in x:  \n",
        "            if int(p) != -1:\n",
        "                # print(char_list[int(p)], end = '')   \n",
        "                words = words+char_list[int(p)]\n",
        "        # print('\\n')\n",
        "        i+=1\n",
        "    return words"
      ],
      "metadata": {
        "id": "FSrpzzjuG8-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_recog_result = ''\n",
        "for i in text_images:\n",
        "  text_recog_result=text_recog_result+' '+predict(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC_pZuP_OQbD",
        "outputId": "ab74d56f-0bf8-4298-f15b-8bf681ab44d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_recog_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "GLAjw4_jP9vT",
        "outputId": "5b1f4310-2dc5-42a9-b153-b9eaa87c8c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' BATCLTE EXPCRT ANTD LIMITED EPort Houe Nosine Surrey GUV21 IYB England Tcn Non RIL n O WAn InITTA roCcO TCA JA  Io 300 Pir NLitoral Torc n r VAT PI 10 Soth FitM Stce C 4002 1816 LoUAYi KotccT Ievoiteto US 265 82 D  Fo Ruirschnoe ALCLC UATY By Sebt FOPCC JD Dr MLC COUIP Pel cbarns in 1901 enrlier PCSS CUC CC Co IAPrT Lelc 25583 rr U5341 40000 180 755555 LUN 192 OEK  C'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = '/content/drive/MyDrive/OCR/ImageAndXML_Data/0000223278.txt'\n",
        "f = open(test_image_path, 'r')\n",
        "file_contents = f.read()\n",
        "print (file_contents)\n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWvg2DUcQyIZ",
        "outputId": "58889768-50fd-4cc2-9f0d-160d91b67322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r> B AT (U.K. and EXPORT) limited Export House Woking Surrey GU211YB England Brown & Williamson International Tobacco, 3000 First National Tower, 101 South Fifth Street, Louisville, Kentucky 40202, U.S.A. Attention Mr. Gory Xhirschncr Telephone Wokin* 76111 Telaeriphic Addreee Export Wokir.* Telex &M101 VAT Reg. No. 239136S to Invoice No.. N I8l6 Date (Tax Point). 26.5.02 By debit in respect of:- 'llalf of Counter Deal charges in 1981 in excess of your earlier estimate. Geoff Harper's telex of 25/5/82 refers*. @ 1.80 US#13,600.00 \n"
          ]
        }
      ]
    }
  ]
}